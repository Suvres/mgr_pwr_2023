\chapter{Wstęp}

\section{Wprowadzenie i uzasadnienie tematu pracy}
Klasyfikacja danych tabelarycznych jest trudnym zagadnieniem do analizy, z powodu powszechnego występowania bardzo dużej ilości nieuporządkowanych danych, które zawierają wiele cech.\ To proces organizowania danych w tabeli w celu ich łatwiejszej analizy, interpretacji czy dalszego przetwarzania.\ Podczas takiej kategoryzacji danych ważne jest właściwe dobranie algorytmu, ze względu na typ danych.\ Przykładowo zbiór danych tekstowych można klasyfikować za pomocą jednokierunkowej sieci neuronowej, a obrazy za pomocą sieci konwolucyjnej.\
\\ \\
Obecnie istnieje wiele różnych algorytmów do klasyfikacji danych tabelarycznych.\ Jednymi z popularniejszych są: regresja logistyczna \trans{ang. logistic regression}, drzewo decyzyjne \trans{ang. decision tree}, las losowy \trans{ang. random forest}, maszyna wektorów nośnych \trans{ang. support vector machine}, naiwny klasyfikator Bayesowski \trans{ang. Naive Bayes classifier}.\ Przy wykorzystaniu tych algorytmów do kategoryzacji, ważne jest właściwe wybranie algorytmu, czyli rozpoznanie z jakimi danymi mamy do czynienia oraz porównanie wyników klasyfikacji, w celu wybrania najlepszego dopasowania.
\\ \\
Dane tabelaryczne występują w każdej dziedzinie, duże zestawy danych można spotkać w medycynie, nauce czy w finansach.\ Rosnąca liczba danych oraz ich zmienna struktura wymaga opracowywania coraz lepszych algorytmów klasyfikacji.\ Jednakże wyjątkowość danych sprawia, że trudno opracować uniwersalny algorytm klasyfikacji.\ Wiele rozwiązań jest tworzonych dla konkretnej struktury danych, co powoduje niemożność ich wykorzystania dla innych danych.
\\ \\
Przy rosnącej liczbie danych do analizy, rozwijają się metody ułatwiające ich klasyfikację. Coraz częściej wykorzystuje się rozwiązania z zakresu sztucznej inteligencji czy obliczeń chmurowych. Jednym z przykładów jest aplikacja \textit{Machine Learning Studio},  dostarczana przez \textit{Microsoft Azure}. Zawiera ona zestaw narzędzi, umożliwiających łatwiejsze kategoryzowanie danych czy tworzenie algorytmów klasyfikacji i ich porównywanie. Użycie chmury pozwala na wykorzystanie mocy obliczeniowej sklasteryzowanych jednostek wirtualnych do wykonywania obliczeń na odpowiednich maszynach wirtualnych czy do budowania skomplikowanych zautomatyzowanych procesów złożonych z wielu zadań \trans{ang. pipeline}. Natomiast wykorzystanie sztucznej inteligencji pozwala na wprowadzenie elementu uczenia się w celu lepszego rozpoznawania danych.
\\ \\
Zastosowanie tych narzędzi umożliwia automatyzację procesu badawczego, porównanie wyników działania różnych algorytmów oraz znaczne przyspieszenie badań.\ Ma to znaczenie przy rosnącym zaprotrzebowaniu na analizę dużych zestawów danych.
\\ \\
W dobie rozwijających się hurtowni danych oraz sztucznej inteligencji coraz więcej firm przetrzymuje ogromne zbiory danych w sieci komputerowej.\ Dane takie mogą być poufne bądź o znaczeniu strategicznym.\ Wyciek takich danych może mieć negatywne konsekwencje dla właścicieli danych bądź osób, których dane sa przechowywane.\ Przykładem może być dostęp do prywatnych kont bankowych albo danych medycznych.\ Dlatego też dane te są zabezpieczane m.in. przy użyciu kryptografii.\ Pozwala to na zaszyfrowanie przesyłu danych poufnych jak i samych przesyłanych danych.\ Jednakże osobom planującym kradzież konkretnych danych dużo bardziej zależy na uzyskanie nieautoryzowanego dostępu do komputerów mogących posiadać dostęp do danych wrażliwych.\ Dzieje się tak, ponieważ dostęp do urządzeń, pozwala na wgląd nie tylko do konkretnych danych ale i do całej sieci intranetowej np. banku.\ Dostęp taki może zostać również wykorzystany do np. wgrania szkodliwego oprogramowania umożliwiającej założenie ,,\textit{tylnej furtki}'' \textit{(ang. backdoor)}.\ W celu ograniczenia możliwych nieautoryzowanych dostępów z zewnątrz powstało oprogramowanie \textit{IDS, IPS} \textit{(ang. Intrusion Detection system, Intrusion Prevent System)}.\ Systemy do ostrzegania i przeciwdziałania atakom na sieć komputerową~\cite{Blyszcz2022}.
\\ \\
Dane sieciowe są bardzo złożone oraz posiadają dużo cech, dlatego do ich analizy można wykorzystać algorytmy uczenia maszynowego pozwalające na wykrycie nietypowego ruchu sieciowego.\ Klasyczne systemy IDS bazują głównie na regułach wykluczających konkretny ruch sieciowy.\ Przewagą uczenia maszynowego jest to, że może wykrywać anomalie niewchodzące w skład reguł bezpieczeństwa w sieci.\ Może to umożliwić przy niewielkim koszcie wytrenowania sieci wczesne i szybsze wykrywanie potencjalnych ataków niż w przypadku klasycznyc hsystemów IDS opartych o reguły.

\section{Cel i zakres pracy}
Celem niniejszej pracy dyplomowej jest ocena jakości opracowanego w pracy inżynierskiej autorskiego sposobu klasyfikacji danych tabelarycznych, wykorzystującego algorytm genetyczny oraz Klasyfikator Naiwny Bayesa.\ W tym celu dokonano analizy porównawczej rozwiązania wraz z algorytmami dostępnymi w aplikacji \textit{Machine Learning Studio}. Algorytmy opisano w Podrozdziale~\ref{sec:alg}.
\\ \\
Praca składa się z 2 części.\ W części teoretycznej (Rozdziały 2 - 5) dokonano przeglądu dostępnych rozwiązań chmurowych (podejścia low-code/no-code).\ Oprócz tego opisano zagadnienia związane ze sztuczną inteligencją.\ W części badawczej (Rozdziały 6 - 8) przygotowano programistyczne stanowisko badawcze.\ W tym celu scharakteryzowano metryki jakościowe i opracowano eksperyment.\ Wykonano analizę porównawczą i statystyczną otrzymanych wyników.\ Dane wykorzystane do badań pochodziły z Instytutu Cyberbezpieczeństwa, działającego przy Uniwersytecie Nowy Brunszwik.

