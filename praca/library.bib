@article{Chen2021,
   abstract = {Tabular data are ubiquitous in real world applications. Although many
commonly-used neural components (e.g., convolution) and extensible neural
networks (e.g., ResNet) have been developed by the machine learning community,
few of them were effective for tabular data and few designs were adequately
tailored for tabular data structures. In this paper, we propose a novel and
flexible neural component for tabular data, called Abstract Layer (AbstLay),
which learns to explicitly group correlative input features and generate
higher-level features for semantics abstraction. Also, we design a structure
re-parameterization method to compress the learned AbstLay, thus reducing the
computational complexity by a clear margin in the reference phase. A special
basic block is built using AbstLays, and we construct a family of Deep Abstract
Networks (DANets) for tabular data classification and regression by stacking
such blocks. In DANets, a special shortcut path is introduced to fetch
information from raw tabular features, assisting feature interactions across
different levels. Comprehensive experiments on seven real-world tabular
datasets show that our AbstLay and DANets are effective for tabular data
classification and regression, and the computational complexity is superior to
competitive methods. Besides, we evaluate the performance gains of DANet as it
goes deep, verifying the extendibility of our method. Our code is available at
https://github.com/WhatAShot/DANet.},
   author = {Jintai Chen and Kuanlun Liao and Yao Wan and Danny Z. Chen and Jian Wu},
   doi = {10.1609/aaai.v36i4.20309},
   isbn = {1577358767},
   issn = {2159-5399},
   journal = {Proceedings of the 36th AAAI Conference on Artificial Intelligence, AAAI 2022},
   month = {12},
   pages = {3930-3938},
   publisher = {Association for the Advancement of Artificial Intelligence},
   title = {DANets: Deep Abstract Networks for Tabular Data Classification and Regression},
   volume = {36},
   url = {https://arxiv.org/abs/2112.02962v4},
   year = {2021},
}
@article{Pedregosa2011,
   author = {F Pedregosa and G Varoquaux and A Gramfort and B Michel V.
and Thirion and O Grisel and M Blondel and R Prettenhofer P.
and Weiss and V Dubourg and J Vanderplas and A Passos and D Cournapeau and M Brucher and M Perrot and E Duchesnay},
   journal = {Journal of Machine Learning Research},
   pages = {2825-2830},
   title = {Scikit-learn: Machine Learning in Python},
   volume = {12},
   year = {2011},
}
@misc{Azure,
   author = {azure},
   title = {Cloud Computing Services | Microsoft Azure},
   url = {https://azure.microsoft.com/en-us/},
}
@misc{Danet,
   author = {danet},
   title = {GitHub - WhatAShot/DANet: DANets (a family of neural networks) for tabular data classification/ regression.},
   url = {https://github.com/WhatAShot/DANet},
}
@article{Blyszcz2022,
   author = {Bartosz Błyszcz},
   city = {Kraków},
   institution = {Akademia Górniczo-Hutnicza im. Stanisława Staszica w Krakowie},
   month = {9},
   title = {Wykorzystanie algorytmów genetycznych w systemach wykrywania intruzów w sieciach komputerowych},
   year = {2022},
}
@misc{unbkaggle,
   author = {UNB},
   title = {IDS 2017 | Datasets | Research | Canadian Institute for Cybersecurity | UNB},
   url = {https://www.unb.ca/cic/datasets/ids-2017.html},
}
@misc{cicds2017kaggle,
   author = {UNB},
   title = {CICIDS2017 | Kaggle},
   url = {https://www.kaggle.com/datasets/cicdataset/cicids2017},
}
@misc{pandas,
   author = {The pandas development team},
   doi = {9.5281/zenodo.3509134},
   month = {2},
   publisher = {Zenodo},
   title = {pandas-dev/pandas: Pandas},
   url = {https://doi.org/9.5281/zenodo.3509134},
   year = {2019},
}
@article{Harris2019,
   author = {Charles R Harris and K Jarrod Millman and Stéfan J.
van der Walt and Ralf Gommers and Pauli Virtanen and David
Cournapeau and Eric Wieser and Julian Taylor and Sebastian
Berg and Nathaniel J Smith and Robert Kern and Matti Picus
and Stephan Hoyer and Marten H van Kerkwijk and Matthew
Brett and Allan Haldane and Jaime Fernández del
Río and Mark Wiebe and Pearu Peterson and Pierre
Gérard-Marchant and Kevin Sheppard and Tyler Reddy and Warren Weckesser and Hameer Abbasi and Christoph Gohlke and Travis E Oliphant},
   doi = {9.1038/s41586-020-2649-2},
   issue = {7824},
   journal = {Nature},
   month = {9},
   pages = {356-362},
   publisher = {Springer Science and Business Media LLC},
   title = {Array programming with NumPy},
   volume = {584},
   url = {https://doi.org/9.1038/s41586-020-2649-2},
   year = {2019},
}
@inproceedings{McKinney2010,
   author = {Wes McKinney},
   doi = {10.25080/Majora-92bf1922-00a},
   pages = {56-61},
   title = {Data Structures for Statistical Computing in Python},
   year = {2010},
}
@misc{azureml,
   author = {Microsoft},
   title = {Microsoft Machine Learning Studio (classic)},
   url = {https://studio.azureml.net/},
}
@article{Wang2003,
   abstract = {Inspired by the sophisticated functionality of human brains where hundreds of billions of interconnected neurons process information in parallel, researchers have successfully tried demonstrating certain levels of intelligence on silicon. Examples include language...},
   author = {Sun-Chong Wang},
   city = {Boston, MA},
   doi = {10.1007/978-1-4615-0377-4_5},
   journal = {Interdisciplinary Computing in Java Programming},
   pages = {81-100},
   publisher = {Springer, Boston, MA},
   title = {Artificial Neural Network},
   url = {https://link.springer.com/chapter/10.1007/978-1-4615-0377-4_5},
   year = {2003},
}
@inbook{OxfordJuly2023,
   author = {Oxford University Press},
   doi = {10.1093/OED/3757635879},
   journal = {Oxford English Dictionary},
   month = {7},
   title = {intelligence, n., sense 1},
   year = {2023},
}
@misc{LinkedInSi,
   author = {Eric Vyacheslav},
   title = {The difference between Artificial Intelligence (AI), Machine Learning},
   url = {https://www.linkedin.com/feed/update/urn:li:activity:7014145513159569408/},
   year = {2023},
}
@article{Mahesh2018,
   abstract = {Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems use to perform a specific task without being explicitly programmed. Learning algorithms in many applications that's we make use of daily. Every time a web search engine like Google is used to search the internet, one of the reasons that work so well is because a learning algorithm that has learned how to rank web pages. These algorithms are used for various purposes like data mining, image processing, predictive analytics, etc. to name a few. The main advantage of using machine learning is that, once an algorithm learns what to do with data, it can do its work automatically. In this paper, a brief review and future prospect of the vast applications of machine learning algorithms has been made.},
   author = {Batta Mahesh},
   doi = {10.21275/ART20203995},
   issn = {2319-7064},
   journal = {International Journal of Science and Research},
   keywords = {Algorithm,Machine Learning,Pseudo Code,Reinforcement learning,Supervised learning,Unsupervised learning},
   title = {Machine Learning Algorithms-A Review},
   url = {https://www.researchgate.net/publication/344717762},
   year = {2018},
}
@article{AiScience,
   doi = {10.1787/A8D820BD-EN},
   journal = {Artificial Intelligence in Science},
   month = {6},
   publisher = {OECD},
   title = {Artificial Intelligence in Science},
   year = {2023},
}
@misc{semiLinkedin,
   author = {Crafsol Technology},
   title = {Semi-Supervised Learning and its Application},
   url = {https://www.linkedin.com/pulse/semi-supervised-learning-its-application-crafsol-technology/},
}
@misc{IBMNetwork,
   author = {IBM},
   title = {What are Neural Networks?},
   url = {https://www.ibm.com/topics/neural-networks},
}
@article{BartosSOM,
   abstract = {Streszczenie: Artykuł prezentuje sieć SOM jako przykład sieci samoorganizującej się. Za-wiera podstawowe informacje o tej sieci: jej genezę, strukturę, sposób funkcjonowania i metodę uczenia (uczenie nienadzorowane z konkurencją). Ponadto autorka opisuje proces weryfikacji samoorganizujących się map cech oraz algorytm Kohonena wykorzystywany podczas trenowania sieci SOM. Słowa kluczowe: sieć neuronowa SOM, algorytm Kohonena, sieć samoorganizująca się.},
   author = {Karolina Bartos},
   issn = {1507-3866},
   keywords = {Kohonen’s algorithm,SOM,algorytm Kohonena,self-organizing neural network,sieć neuronowa SOM,sieć samoorganizująca się},
   title = {SIEĆ SOM JAKO PRZYKŁAD SIECI SAMOORGANIZUJĄCEJ SIĘ},
   year = {2012},
}
@article{Fradkov2020,
   abstract = {Machine learning belongs to the crossroad of cybernetics (control science) and computer science. It is attracting recently an overwhelming interest, both of professionals and of the general public. In the talk a brief overview of the historical development of the machine learning field with a focus on the development of mathematical apparatus in its first decades is provided. A number of little-known facts published in hard to reach sources are presented.},
   author = {Alexander L. Fradkov},
   doi = {10.1016/J.IFACOL.2020.12.1888},
   issn = {2405-8963},
   issue = {2},
   journal = {IFAC-PapersOnLine},
   keywords = {Convex optimization,Machine learning,Neural networks,Separation theorems},
   month = {1},
   pages = {1385-1390},
   publisher = {Elsevier},
   title = {Early History of Machine Learning},
   volume = {53},
   year = {2020},
}
@misc{Koch2022,
   author = {Robert Koch},
   title = {History of Machine Learning - A Journey through the Timeline},
   url = {https://www.clickworker.com/customer-blog/history-of-machine-learning/},
   year = {2022},
}
@misc{MicrosoftDeep2023,
   author = {Microsoft},
   title = {Deep learning vs. machine learning - Azure Machine Learning},
   url = {https://learn.microsoft.com/en-us/azure/machine-learning/concept-deep-learning-vs-machine-learning?view=azureml-api-2},
   year = {2023},
}
@misc{Algolytics,
   author = {Algolytics},
   title = {Jak ocenić jakość i poprawność modeli klasyfikacyjnych? Część 4 - Krzywa ROC},
   url = {https://algolytics.pl/tutorial-jak-ocenic-jakosc-i-poprawnosc-modeli-klasyfikacyjnych-czesc-4-krzywa-roc/},
}
@article{Rokis2022,
   abstract = {Low-code/no-code software development is an emerging approach delivering the opportunity to build software with a minimal need for manual coding and enhancing the involvement of non-programmers in software development. Low-code principles allow enterprises to save time and costs through a more rapid development pace and to improve software products quality by bringing closer together business and information technologies as well as promoting automation. Nevertheless, the low-code/no-code approach is a relatively new and continuously progressing domain that requires understanding of existing challenges and identification of improvement directions. In this paper, challenges in the low-code software development process and suggestions for their mitigation are identified and amalgamated with the purpose to deliver insights into the current state of the low-code/no-code development process and identify areas for further research and development.},
   author = {Karlis Rokis and Marite Kirikova},
   doi = {10.1007/978-3-031-16947-2_1/COVER},
   isbn = {9783031169465},
   issn = {18651356},
   journal = {Lecture Notes in Business Information Processing},
   keywords = {Citizen developer,Low-code,Low-code development platform,No-code,Requirements,Software development},
   pages = {3-17},
   publisher = {Springer Science and Business Media Deutschland GmbH},
   title = {Challenges of Low-Code/No-Code Software Development: A Literature Review},
   volume = {462 LNBIP},
   url = {https://link.springer.com/chapter/10.1007/978-3-031-16947-2_1},
   year = {2022},
}
@article{Hirzel2022,
   abstract = {Traditionally, computer programming has been the prerogative of professional
developers using textual programming languages such as C, Java, or Python.
Low-code programming promises an alternative: letting citizen developers create
programs using visual abstractions, demonstrations, or natural language. While
low-code programming is currently getting a lot of attention in industry, the
relevant research literature is scattered, and in fact, rarely uses the term
"low-code". This article brings together low-code literature from various
research fields, explaining how techniques work while providing a unified point
of view. Low-code has the potential to empower more people to automate tasks by
creating computer programs, making them more productive and less dependent on
scarce professional software developers.},
   author = {Martin Hirzel},
   month = {5},
   title = {Low-Code Programming Models},
   url = {https://arxiv.org/abs/2205.02282v1},
   year = {2022},
}
@misc{Wordpress2023,
   author = {Wordpress.com},
   title = {WordPress.com: Build a Site, Sell Your Stuff, Start a Blog & More},
   url = {https://wordpress.com/},
   year = {2023},
}
@misc{Joomla2023,
   author = {Joomla},
   title = {Joomla Content Management System (CMS) - try it! It's free!},
   url = {https://www.joomla.org/},
   year = {2023},
}
@misc{Wix2023,
   author = {Wix.com},
   title = {Website Builder - Create a Free Website Today},
   url = {https://www.wix.com/},
   year = {2023},
}
@misc{Powerapps2023,
   author = {Microsoft},
   title = {PowerApps},
   url = {https://guidedtour.microsoft.com/guidedtour/scenarios/power-apps/2.2.png},
   year = {2023},
}
@misc{WordpressDeveloper2023,
   author = {Wordpress},
   title = {Playground Demo},
   url = {https://developer.wordpress.org/playground/demo/},
   year = {2023},
}
